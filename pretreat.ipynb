{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "from os import path, listdir\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import waymo_open_dataset\n",
    "from waymo_open_dataset.utils import  frame_utils\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
    "import utils\n",
    "from utils import extract_and_serialize_frame, deserialize_example, extract_frame_features\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import math\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def convert_waymo_data(tar_dir, temp_dir, tgt_dir, start, end):\n",
    "    tars = [path.join(tar_dir, file) for file in listdir(tar_dir)][start:end]\n",
    "    print(tars)\n",
    "\n",
    "    for (idx, tar) in enumerate(tars):\n",
    "        print(f\"Extracting {tar} to {temp_dir}\")\n",
    "        tar_file = tarfile.open(tar, 'r:')\n",
    "        tar_file.extractall(temp_dir)\n",
    "        tar_file.close()\n",
    "\n",
    "        parsed_file = path.join(tgt_dir, 'parsed-' + str(idx).rjust(3, '0') + '.tfrecord')\n",
    "        license_file = f'{temp_dir}/LICENSE'\n",
    "\n",
    "        print(f'Deleting LICENSE file {temp_dir}/LICENSE')\n",
    "        if path.exists(license_file):\n",
    "            os.remove(license_file)\n",
    "        temp_files = [f'{temp_dir}/{file}' for file in listdir(temp_dir)]\n",
    "\n",
    "        print(f\"Parsing data and writing to {parsed_file}\")\n",
    "        dataset = tf.data.TFRecordDataset(temp_files)\n",
    "        writer = tf.io.TFRecordWriter(parsed_file)\n",
    "        for (idx, data) in enumerate(dataset):\n",
    "            if idx % 100 == 0:\n",
    "                print(f'Processed {idx} frames')\n",
    "            converted = extract_and_serialize_frame(data)\n",
    "            writer.write(converted)\n",
    "        writer.close()\n",
    "\n",
    "        print(f\"Deleting temp files from {temp_dir}\")\n",
    "        for file in temp_files:\n",
    "            os.remove(file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "convert_waymo_data('Data/unprocessed/training', 'Data/temp/training', 'Data/parsed/training', 0, 32)\n",
    "convert_waymo_data('Data/unprocessed/validation', 'Data/temp/validation', 'Data/parsed/validation', 0, 8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "SCALE_PCT = 0.5\n",
    "\n",
    "def convert_to_darknet(src_dir, tgt_dir, index_file):\n",
    "    files = [path.join(src_dir, file) for file in listdir(src_dir)]\n",
    "    img_id = len(listdir(f'{tgt_dir}/obj')) // 2\n",
    "    \n",
    "    for (idx, file) in enumerate(files):\n",
    "        print(f\"Converting {file} to {tgt_dir} ({idx + 1} of {len(files)})\")\n",
    "\n",
    "        dataset = tf.data.TFRecordDataset(file)\n",
    "        for data in dataset:\n",
    "            example = deserialize_example(data)\n",
    "            og_width = example['width'].numpy()\n",
    "            og_height = example['height'].numpy()\n",
    "            img_width = int(og_width * SCALE_PCT)\n",
    "            img_height = int(og_height * SCALE_PCT)\n",
    "\n",
    "            image = Image.fromarray(tf.io.decode_jpeg(example['raw_image']).numpy())\n",
    "            image = image.resize((img_height, img_width))\n",
    "\n",
    "            image_name = f'example-{img_id}.jpg'\n",
    "            image.save(f'{tgt_dir}/obj/{image_name}')\n",
    "            \n",
    "            classes = example['class'].numpy()\n",
    "            boxes_center_y = example['box_center_y'].numpy()\n",
    "            boxes_center_x = example['box_center_x'].numpy()\n",
    "            boxes_width = example['box_width'].numpy()\n",
    "            boxes_height = example['box_height'].numpy()\n",
    "            label_name = f'example-{img_id}.txt'\n",
    "            with open(f'{tgt_dir}/obj/{label_name}', 'w') as label_file:\n",
    "                for (clazz, cx, cy, w, h) in zip(classes, boxes_center_x, boxes_center_y, boxes_height, boxes_width):\n",
    "                    cx /= og_width\n",
    "                    cy /= og_height\n",
    "                    w /= og_width\n",
    "                    h /= og_height\n",
    "                    darknet_labels = f'{clazz} {cx} {cy} {w} {h}\\n'\n",
    "                    label_file.write(darknet_labels)\n",
    "            \n",
    "            index_file.write(f'data/obj/{image_name}\\n')\n",
    "            img_id += 1\n",
    "\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('Data/darknet-data/training.txt', 'w') as training_index:\n",
    "    convert_to_darknet('Data/processed/training', 'Data/darknet-data', training_index)\n",
    "\n",
    "with open('Data/darknet-data/validation.txt', 'w') as validation_index:\n",
    "    convert_to_darknet('Data/processed/validation', 'Data/darknet-data', validation_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.12 64-bit ('mti830': conda)"
  },
  "interpreter": {
   "hash": "32a546c37cb5454deb6caa194aa602f857ba2d1d6ca86a6f67cf7d8194a16d99"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}