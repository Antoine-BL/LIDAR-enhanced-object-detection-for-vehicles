{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from descartes import PolygonPatch\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "import alphashape\n",
    "import cv2\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import open3d as o3d\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
    "from waymo_open_dataset.utils import range_image_utils\n",
    "from waymo_open_dataset.utils import transform_utils\n",
    "from waymo_open_dataset.utils import  frame_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17752/142025742.py:62: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  exteriors = [int_coords(poly.exterior.coords) for poly in alpha_shape]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = ['Data/lidar tests/training/' + file for file in os.listdir('Data/lidar tests/training')]\n",
    "dataset = tf.data.TFRecordDataset(files, buffer_size=tf.constant(int(pow(10,6)), tf.int64), num_parallel_reads=16)\n",
    "OUTPUT_PATH = 'Data/darknet-data'\n",
    "SCALE_PCT = 0.5\n",
    "img_id = len(os.listdir(f'{OUTPUT_PATH}/obj')) // 2\n",
    "\n",
    "def label_in_polygon(label, image):\n",
    "    top_left_x = int(math.ceil(label.box.center_x - label.box.length / 2))\n",
    "    top_left_y = int(math.ceil(label.box.center_y - label.box.width / 2))\n",
    "    bottom_right_x = int(math.ceil(label.box.center_x + label.box.length / 2))\n",
    "    bottom_right_y = int(math.ceil(label.box.center_y + label.box.width / 2))\n",
    "    cropped = image[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "    nb_pixels = cropped.size\n",
    "    nonzero = np.count_nonzero(cropped)\n",
    "    return (nonzero / nb_pixels) > 0.25\n",
    "\n",
    "training_index = open('Data/darknet-data/training.txt', 'w')\n",
    "for data in dataset:\n",
    "    frame = open_dataset.Frame()\n",
    "    frame.ParseFromString(bytearray(data.numpy()))\n",
    "    image = frame.images[0]\n",
    "    image = np.array(tf.io.decode_jpeg(image.image))\n",
    "\n",
    "    if np.mean(image) < 100:\n",
    "        continue\n",
    "\n",
    "    (range_images, camera_projections, _, range_image_top_pose) = frame_utils.parse_range_image_and_camera_projection(frame)\n",
    "    points, cp_points = frame_utils.convert_range_image_to_point_cloud(\n",
    "    frame,\n",
    "    range_images,\n",
    "    camera_projections,\n",
    "    range_image_top_pose)\n",
    "    points_ri2, cp_points_ri2 = frame_utils.convert_range_image_to_point_cloud(\n",
    "        frame,\n",
    "        range_images,\n",
    "        camera_projections,\n",
    "        range_image_top_pose,\n",
    "        ri_index=1)\n",
    "    # 3d points in vehicle frame.\n",
    "    points_all = np.concatenate(points, axis=0)\n",
    "    points_all_ri2 = np.concatenate(points_ri2, axis=0)\n",
    "    # camera projection corresponding to each point.\n",
    "    cp_points_all = np.concatenate(cp_points, axis=0)\n",
    "    cp_points_all_ri2 = np.concatenate(cp_points_ri2, axis=0)\n",
    "\n",
    "    all_points = np.append(points_all, points_all_ri2, axis=0)\n",
    "    all_points_cp = np.append(cp_points_all, cp_points_all_ri2, axis=0)\n",
    "\n",
    "    front_points = np.array([point for (point, cp) in zip(all_points, all_points_cp) if cp[0] == 1 or cp[3] == 1])\n",
    "    front_cp_points = np.array([cp[:3] if cp[0] == 1 else cp[3:] for cp in all_points_cp if cp[0] == 1 or cp[3] == 1])\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(front_points)\n",
    "    plane_model, inliers = pcd.segment_plane(distance_threshold=0.1, ransac_n=4, num_iterations=1000)\n",
    "\n",
    "    front_cp_points_no_road = np.delete(front_cp_points, inliers, axis=0)\n",
    "\n",
    "    alpha_shape = alphashape.alphashape(front_cp_points_no_road[:,1:3], 0.02)\n",
    "    int_coords = lambda x: np.array(x).round().astype(np.int32)\n",
    "\n",
    "    try:\n",
    "        exteriors = [int_coords(poly.exterior.coords) for poly in alpha_shape]\n",
    "    except:\n",
    "        exteriors = [int_coords(poly.exterior.coords) for poly in [alpha_shape]]\n",
    "\n",
    "    mask = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "    cv2.fillPoly(mask, exteriors, 1)\n",
    "    image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    labels = [camera_labels.labels for camera_labels in frame.camera_labels if camera_labels.name == 1][0]\n",
    "    labels = [label for label in labels if label.box.length > 50 and label.box.length > 50 and label_in_polygon(label, image)]\n",
    "\n",
    "    og_width = image.shape[1]\n",
    "    og_height = image.shape[0]\n",
    "    img_width = int(og_width * SCALE_PCT)\n",
    "    img_height = int(og_height * SCALE_PCT)\n",
    "    image = Image.fromarray(image)    \n",
    "    image = image.resize((img_width, img_height))\n",
    "\n",
    "    image_name = f'example-{img_id}.jpg'\n",
    "    image.save(f'{OUTPUT_PATH}/obj/{image_name}')\n",
    "\n",
    "    label_name = f'example-{img_id}.txt'\n",
    "    with open(f'{OUTPUT_PATH}/obj/{label_name}', 'w') as label_file:\n",
    "        for label in labels:\n",
    "            cx = label.box.center_x \n",
    "            cy = label.box.center_y\n",
    "            w = label.box.length\n",
    "            h = label.box.width\n",
    "            cx /= og_width\n",
    "            cy /= og_height\n",
    "            w /= og_width\n",
    "            h /= og_height\n",
    "            clazz = label.type\n",
    "            darknet_labels = f'{clazz} {cx} {cy} {w} {h}\\n'\n",
    "            label_file.write(darknet_labels)\n",
    "\n",
    "    training_index.write(f'data/obj/{image_name}\\n')\n",
    "    img_id += 1\n",
    "\n",
    "training_index.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['Data/lidar tests/validation/' + file for file in os.listdir('Data/lidar tests/validation')]\n",
    "\n",
    "validation_index = open('Data/darknet-data/validation.txt', 'w')\n",
    "img_id = len(os.listdir(f'{OUTPUT_PATH}/obj')) // 2\n",
    "def label_in_polygon(label, image):\n",
    "    top_left_x = int(math.ceil(label.box.center_x - label.box.length / 2))\n",
    "    top_left_y = int(math.ceil(label.box.center_y - label.box.width / 2))\n",
    "    bottom_right_x = int(math.ceil(label.box.center_x + label.box.length / 2))\n",
    "    bottom_right_y = int(math.ceil(label.box.center_y + label.box.width / 2))\n",
    "    cropped = image[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "    nb_pixels = cropped.size\n",
    "    nonzero = np.count_nonzero(cropped)\n",
    "    return (nonzero / nb_pixels) > 0.25\n",
    "\n",
    "\n",
    "for data in dataset:\n",
    "    frame = open_dataset.Frame()\n",
    "    frame.ParseFromString(bytearray(data.numpy()))\n",
    "    image = frame.images[0]\n",
    "    image = np.array(tf.io.decode_jpeg(image.image))\n",
    "\n",
    "    if np.mean(image) < 100:\n",
    "        continue\n",
    "\n",
    "    (range_images, camera_projections, _, range_image_top_pose) = frame_utils.parse_range_image_and_camera_projection(frame)\n",
    "    points, cp_points = frame_utils.convert_range_image_to_point_cloud(\n",
    "    frame,\n",
    "    range_images,\n",
    "    camera_projections,\n",
    "    range_image_top_pose)\n",
    "    points_ri2, cp_points_ri2 = frame_utils.convert_range_image_to_point_cloud(\n",
    "        frame,\n",
    "        range_images,\n",
    "        camera_projections,\n",
    "        range_image_top_pose,\n",
    "        ri_index=1)\n",
    "    # 3d points in vehicle frame.\n",
    "    points_all = np.concatenate(points, axis=0)\n",
    "    points_all_ri2 = np.concatenate(points_ri2, axis=0)\n",
    "    # camera projection corresponding to each point.\n",
    "    cp_points_all = np.concatenate(cp_points, axis=0)\n",
    "    cp_points_all_ri2 = np.concatenate(cp_points_ri2, axis=0)\n",
    "\n",
    "    all_points = np.append(points_all, points_all_ri2, axis=0)\n",
    "    all_points_cp = np.append(cp_points_all, cp_points_all_ri2, axis=0)\n",
    "\n",
    "    front_points = np.array([point for (point, cp) in zip(all_points, all_points_cp) if cp[0] == 1 or cp[3] == 1])\n",
    "    front_cp_points = np.array([cp[:3] if cp[0] == 1 else cp[3:] for cp in all_points_cp if cp[0] == 1 or cp[3] == 1])\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(front_points)\n",
    "    plane_model, inliers = pcd.segment_plane(distance_threshold=0.1, ransac_n=4, num_iterations=1000)\n",
    "\n",
    "    front_cp_points_no_road = np.delete(front_cp_points, inliers, axis=0)\n",
    "\n",
    "    alpha_shape = alphashape.alphashape(front_cp_points_no_road[:,1:3], 0.02)\n",
    "    int_coords = lambda x: np.array(x).round().astype(np.int32)\n",
    "\n",
    "    try:\n",
    "        exteriors = [int_coords(poly.exterior.coords) for poly in alpha_shape]\n",
    "    except:\n",
    "        exteriors = [int_coords(poly.exterior.coords) for poly in [alpha_shape]]\n",
    "\n",
    "    mask = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "    cv2.fillPoly(mask, exteriors, 1)\n",
    "    image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    labels = [camera_labels.labels for camera_labels in frame.camera_labels if camera_labels.name == 1][0]\n",
    "    labels = [label for label in labels if label.box.length > 50 and label.box.length > 50 and label_in_polygon(label, image)]\n",
    "\n",
    "    og_width = image.shape[1]\n",
    "    og_height = image.shape[0]\n",
    "    img_width = int(og_width * SCALE_PCT)\n",
    "    img_height = int(og_height * SCALE_PCT)\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((img_width, img_height))\n",
    "\n",
    "    image_name = f'example-{img_id}.jpg'\n",
    "    image.save(f'{OUTPUT_PATH}/obj/{image_name}')\n",
    "\n",
    "    label_name = f'example-{img_id}.txt'\n",
    "    with open(f'{OUTPUT_PATH}/obj/{label_name}', 'w') as label_file:\n",
    "        for label in labels:\n",
    "            cx = label.box.center_x \n",
    "            cy = label.box.center_y\n",
    "            w = label.box.length\n",
    "            h = label.box.width\n",
    "            cx /= og_width\n",
    "            cy /= og_height\n",
    "            w /= og_width\n",
    "            h /= og_height\n",
    "            clazz = label.type\n",
    "            darknet_labels = f'{clazz} {cx} {cy} {w} {h}\\n'\n",
    "            label_file.write(darknet_labels)\n",
    "\n",
    "    validation_index.write(f'data/obj/{image_name}\\n')\n",
    "    img_id += 1\n",
    "\n",
    "validation_index.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mti830-3d')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b69184622dfefc4f97e5135018ed6d3c41e22e1b75804b24dc791ffa51790783"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
